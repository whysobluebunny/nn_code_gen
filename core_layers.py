from layer import Layer
from kb_support import KernelBiasSupport


# Just your regular densely-connected NN layer.

# units: Positive integer, dimensionality of the output space.
# activation: Activation function to use.
# If you don't specify anything, no activation is applied (ie. "linear" activation: a(x) = x).
# use_bias: Boolean, whether the layer uses a bias vector.
# kernel_initializer: Initializer for the kernel weights matrix.
# bias_initializer: Initializer for the bias vector.
# kernel_regularizer: Regularizer function applied to the kernel weights matrix.
# bias_regularizer: Regularizer function applied to the bias vector.
# activity_regularizer: Regularizer function applied to the output of the layer (its "activation").
# kernel_constraint: Constraint function applied to the kernel weights matrix.
# bias_constraint: Constraint function applied to the bias vector.

# keras.layers.Dense(units, activation=None, use_bias=True,
# kernel_initializer='glorot_uniform', bias_initializer='zeros',
# kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,
# kernel_constraint=None, bias_constraint=None)
class Dense(Layer, KernelBiasSupport):
    def __init__(self, units=None, activation=None, use_bias=True, kernel_initializer=None,
                 bias_initializer=None, kernel_regularizer=None, bias_regularizer=None,
                 activity_regularizer=None, kernel_constraint=None, bias_constraint=None):
        Layer.__init__(self)
        KernelBiasSupport.__init__(self, use_bias, kernel_initializer, bias_initializer, kernel_regularizer,
                                   bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint)
        self.units = units
        self.activation = activation
        self.name = 'Dense'

    def set_units(self, value):
        self.units = value

    def set_activation(self, value):
        self.activation = value


# Applies an activation function to an output.

# activation: Activation function, such as tf.nn.relu, or string name of built-in activation function, such as "relu".

# keras.layers.Activation(activation)
class Activation(Layer):
    def __init__(self):
        Layer.__init__(self)
        self.activation = None
        self.name = 'Activation'

    def set_activation(self, value):
        self.activation = value


# Applies Dropout to the input.

# rate: Float between 0 and 1. Fraction of the input units to drop.
# noise_shape: 1D integer tensor representing the shape of the binary dropout mask that will be
# multiplied with the input. For instance, if your inputs have shape (batch_size, timesteps, features)
# and you want the dropout mask to be the same for all timesteps, you can use noise_shape=(batch_size, 1, features).
# seed: A Python integer to use as random seed.

# keras.layers.Dropout(rate, noise_shape=None, seed=None)
class Dropout(Layer):
    def __init__(self, rate=None, noise_shape=None, seed=None):
        Layer.__init__(self)
        self.rate = rate
        self.noise_shape = noise_shape
        self.seed = seed
        self.name = 'Dropout'

    def set_rate(self, value):
        self.rate = value

    def set_noise_shape(self, value):
        self.noise_shape = value

    def set_seed(self, value):
        self.seed = value


# keras.layers.Flatten(data_format=None)
class Flatten(Layer):
    def __init__(self, data_format=None):
        Layer.__init__(self)
        self.data_format = data_format
        self.name = 'Flatten'

    def set_data_format(self, value):
        self.data_format = value


# Input() is used to instantiate a Keras tensor.

# shape: A shape tuple (integers), not including the batch size. For instance, shape=(32,)
# indicates that the expected input will be batches of 32-dimensional vectors.
# Elements of this tuple can be None; 'None' elements represent dimensions where the shape is not known.
# batch_size: optional static batch size (integer).
# name: An optional name string for the layer. Should be unique in a model (do not reuse the same name twice).
# It will be autogenerated if it isn't provided.
# dtype: The data type expected by the input, as a string (float32, float64, int32...)
# sparse: A boolean specifying whether the placeholder to be created is sparse.
# Only one of 'ragged' and 'sparse' can be True. Note that, if sparse is False,
# sparse tensors can still be passed into the input - they will be densified with a default value of 0.
# tensor: Optional existing tensor to wrap into the Input layer. If set, the layer will use the tf.TypeSpec
# of this tensor rather than creating a new placeholder tensor.

# keras.engine.input_layer.Input()
class Input(Layer):
    def __init__(self, shape=None, batch_shape=None, dtype=None, sparse=None, tensor=None):
        Layer.__init__(self)
        self.shape = shape
        self.batch_shape = batch_shape
        self.dtype = dtype
        self.sparse = sparse
        self.tensor = tensor
        self.name = 'Input'

    def set_shape(self, value):
        self.shape = value

    def set_batch_shape(self, value):
        self.batch_shape = value

    def set_dtype(self, value):
        self.dtype = value

    def set_sparse(self, value):
        self.sparse = value

    def set_tensor(self, value):
        self.tensor = value
